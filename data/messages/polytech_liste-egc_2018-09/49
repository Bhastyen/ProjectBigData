Return-Path: <pierre-francois.marteau@univ-ubs.fr>
X-Original-To: polytech_liste-egc@sympa6.univ-nantes.prive
Delivered-To: polytech_liste-egc@sympa6.univ-nantes.prive
Received: from bouncesmtp2.univ-nantes.fr (BounceSMTP2.univ-nantes.prive [172.20.12.67])
	by sympa6.univ-nantes.prive (Postfix) with ESMTP id 323C72292956
	for <polytech_liste-egc@sympa6.univ-nantes.prive>; Mon, 24 Sep 2018 11:52:30 +0200 (CEST)
Received: from mx3.d101.univ-nantes.fr (MX3.univ-nantes.fr [193.52.101.137])
	by bouncesmtp2.univ-nantes.fr (Postfix) with ESMTP id 30A11628825
	for <polytech_liste-egc@sympa6.univ-nantes.prive>; Mon, 24 Sep 2018 11:52:30 +0200 (CEST)
Received: from localhost (localhost [127.0.0.1])
	by mx3.d101.univ-nantes.fr (Postfix) with ESMTP id 2C37F43C6A0B
	for <liste-egc@polytech.univ-nantes.fr>; Mon, 24 Sep 2018 11:52:30 +0200 (CEST)
X-Virus-Scanned: Debian amavisd-new at univ-nantes.fr
X-Spam-Flag: NO
X-Spam-Score: -5.769
X-Spam-Level:
X-Spam-Status: No, score=-5.769 tagged_above=-1000 required=5
	tests=[CRM114_GOOD=-5, HTML_MESSAGE=0.001, NO_RDNS2=0.01,
	RCVD_IN_DNSWL_LOW=-1, RCVD_IN_WSFF=0.01, SPF_PASS=-0.001,
	T_FRT_PROFILE1=0.01, UN_PHISHING_COMPTE=0.1, UN_PHISHING_PW=0.1,
	URIBL_BLOCKED=0.001] autolearn=disabled
X-CRM114-Status: GOOD ( 5.1896 )
X-CRM114-CacheID: 
Received: from mx3.d101.univ-nantes.fr ([127.0.0.1])
	by localhost (univ-nantes.fr [127.0.0.1]) (amavisd-new, port 10024)
	with ESMTP id L30DzQ2snG7v for <liste-egc@polytech.univ-nantes.fr>;
	Mon, 24 Sep 2018 11:52:27 +0200 (CEST)
X-Greylist: domain auto-whitelisted by SQLgrey-1.6.7
Received: from smtpout20.partage.renater.fr (smtpout02-ext1.partage.renater.fr [194.254.241.32])
	by mx3.d101.univ-nantes.fr (Postfix) with ESMTP id 7B055401C113
	for <liste-egc@polytech.univ-nantes.fr>; Mon, 24 Sep 2018 11:52:27 +0200 (CEST)
Received: from zmtaout02.partage.renater.fr (zmtaout02.partage.renater.fr [194.254.241.30])
	by smtpout20.partage.renater.fr (Postfix) with ESMTP id 6C9B1BFC60
	for <liste-egc@polytech.univ-nantes.fr>; Mon, 24 Sep 2018 11:52:26 +0200 (CEST)
Received: from zmtaout02.partage.renater.fr (localhost [127.0.0.1])
	by zmtaout02.partage.renater.fr (Postfix) with ESMTPS id 604332007A
	for <liste-egc@polytech.univ-nantes.fr>; Mon, 24 Sep 2018 11:52:26 +0200 (CEST)
Received: from localhost (localhost [127.0.0.1])
	by zmtaout02.partage.renater.fr (Postfix) with ESMTP id 4FC24200A0
	for <liste-egc@polytech.univ-nantes.fr>; Mon, 24 Sep 2018 11:52:26 +0200 (CEST)
X-Virus-Scanned: amavisd-new at zmtaout02.partage.renater.fr
Received: from zmtaout02.partage.renater.fr ([127.0.0.1])
	by localhost (zmtaout02.partage.renater.fr [127.0.0.1]) (amavisd-new, port 10026)
	with ESMTP id XA339fLuXduX for <liste-egc@polytech.univ-nantes.fr>;
	Mon, 24 Sep 2018 11:52:26 +0200 (CEST)
Received: from [193.50.241.118][10.2.147.178] (lb01.partage.renater.fr [194.254.242.1])
	by zmtaout02.partage.renater.fr (Postfix) with ESMTPA id 17C3F2007A
	for <liste-egc@polytech.univ-nantes.fr>; Mon, 24 Sep 2018 11:52:26 +0200 (CEST)
To: liste-egc@polytech.univ-nantes.fr
From: Pierre-Francois Marteau <pierre-francois.marteau@univ-ubs.fr>
Message-ID: <1a643ca0-ff3b-155d-653a-e9c13961227a@univ-ubs.fr>
Date: Mon, 24 Sep 2018 11:52:25 +0200
User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:52.0) Gecko/20100101
 Thunderbird/52.9.1
MIME-Version: 1.0
Content-Type: multipart/alternative;
 boundary="------------CADEA4D00676B49915C6E3C7"
Content-Language: en-US
X-Validation-by: p_bruneau@hotmail.com
Subject: [liste-egc] =?UTF-8?Q?Th=C3=A8se?= CIFRE : Clustering adaptatif
 =?UTF-8?Q?=28semi-supervis=C3=A9=29?= de
 =?UTF-8?Q?donn=C3=A9es_=C3=A9conomiques_h=C3=A9t=C3=A9rog=C3=A8nes?=

This is a multi-part message in MIME format.
--------------CADEA4D00676B49915C6E3C7
Content-Type: text/plain; charset=utf-8; format=flowed
Content-Transfer-Encoding: quoted-printable

Offre de th=C3=A8se CIFRE : Clustering adaptatif (semi-supervis=C3=A9) de=
 donn=C3=A9es=20
=C3=A9conomiques h=C3=A9t=C3=A9rog=C3=A8nes

Contexte scientifique

=C3=80 l'=C3=A8re du d=C3=A9luge des donn=C3=A9es, le clustering interact=
if (ou plus=20
largement les techniques de classification semi-supervis=C3=A9e ou encore=
=20
bas=C3=A9e sur un apprentissage actif)=C2=A0 suscite de plus en plus d'at=
tention=20
dans les communaut=C3=A9s de la fouille des donn=C3=A9es (en particulier =
l=E2=80=99analyse=20
exploratoire des donn=C3=A9es) et de l=E2=80=99apprentissage automatique.=
 L'objectif=20
cibl=C3=A9 est de faire converger les r=C3=A9sultats d=E2=80=99un cluster=
ing vers un=20
objectif plus ou moins bien formalis=C3=A9 en utilisant une supervision=20
limit=C3=A9e. En g=C3=A9n=C3=A9ral, le clustering semi-supervis=C3=A9 exp=
loite ainsi un=20
nombre limit=C3=A9 d=E2=80=99exemples (=C3=A9tiquet=C3=A9s), ou un ensemb=
le de contraintes (un=20
sous-ensemble d=E2=80=99objets doivent imp=C3=A9rativement =C3=AAtre asso=
ci=C3=A9s dans un m=C3=AAme=20
cluster (ou au contraire doivent =C3=AAtre affect=C3=A9s dans les cluster=
s=20
distincts), etc. La complexit=C3=A9 algorithmique est l=E2=80=99un des fr=
eins au=20
d=C3=A9veloppement des approches de clustering (complexit=C3=A9 souvent=20
quadratique). Les approches r=C3=A9centes veillent =C3=A0 ma=C3=AEtriser =
cette=20
complexit=C3=A9. C=E2=80=99est le cas par exemple pour l=E2=80=99approche=
=20
=E2=80=9C=C3=A9clatement/regroupement=E2=80=9D associ=C3=A9e =C3=A0 un cl=
ustering exploratoire propos=C3=A9e=20
dans [Cutting et al., 2017].

Les travaux sur le clustering interactif exploitent des informations=20
supervis=C3=A9es qui se r=C3=A9partissant dans l=E2=80=99une des trois or=
ientations=20
suivantes :

1) Les approches bas=C3=A9es sur la sp=C3=A9cification de contraintes=C2=A0=
: on=20
retrouve dans cette cat=C3=A9gorie les m=C3=A9thodes Kmeans, kernel-Kmean=
s,=20
clustering hi=C3=A9rarchique, allocation de Dirichlet Latent (LDA) et=20
d=C3=A9riv=C3=A9es [Archambeau et al., 2014], les m=C3=A9thodes de cluste=
ring de=20
graphe, le co-clustering, etc.

2) Les approches bas=C3=A9es apprentissage de m=C3=A9trique (metric learn=
ing) qui=20
adaptent la mesure de similarit=C3=A9 utilis=C3=A9e par l'algorithme de=20
classification. Lorsque, par exemple, seules les contraintes par paires=20
sont disponibles (telles que les contraintes =C2=ABmust-link=C2=BB ou=20
=C2=ABcannot-link=C2=BB) [Basu et al., 2009], [Yin et al., 2010] ou [Yin =
et al.,=20
2012], les approches bas=C3=A9es sur des graphes peuvent s'av=C3=A9rer tr=
=C3=A8s=20
efficaces. Par exemple, [Kang et al., 2017] d=C3=A9veloppent un algorithm=
e=20
permettant de clusteriser un graphe (de similarit=C3=A9) en tenant compte=
 des=20
structures locales et globales du manifold sur lequel se r=C3=A9partissen=
t=20
les donn=C3=A9es.

3) Les approches mixtes=C2=A0: dans [Dhillon et al., 2004] par exemple, d=
es=20
approches exploitant des repr=C3=A9sentations vectorielles et des graphes=
=20
sont unifi=C3=A9es en utilisant un algorithme de type kernel k-means=C2=A0=
=20
pond=C3=A9r=C3=A9. Faisant suite =C3=A0 de nombreux travaux sur l'apprent=
issage de=20
m=C3=A9trique comme dans [Schultz et Joachims, 2004], l'int=C3=A9gration =
des=20
contraintes par paires et de l'apprentissage de distance est d=C3=A9velop=
p=C3=A9e=20
dans un cadre de classification K-means par [Bielenko et al. 2004]. Une=20
approche d'optimisation est alors adopt=C3=A9e permettant l'int=C3=A9grat=
ion de=20
contraintes et de param=C3=A8tres m=C3=A9triques dans une seule fonctionn=
elle.
Objectifs de la th=C3=A8se

Les travaux de th=C3=A8se propos=C3=A9s concernent le clustering adaptati=
f=20
(incluant un processus de semi-supervision) de donn=C3=A9es =C3=A9conomiq=
ues=20
h=C3=A9t=C3=A9rog=C3=A8nes. Il s=E2=80=99agit de concevoir une cha=C3=AEn=
e de traitement des donn=C3=A9es=20
construite autour d=E2=80=99un clustering interactif qui permet :

- d=E2=80=99exploiter des outils d=E2=80=99extraction d=E2=80=99informati=
ons (structur=C3=A9es ou=20
semi-structur=C3=A9es) supervis=C3=A9es de type entit=C3=A9 nomm=C3=A9es =
(le nom d=E2=80=99une=20
entreprise, d=E2=80=99une commune ou d=E2=80=99une ville), ou des relatio=
ns entre=20
concepts (relation associant des lots =C3=A0 des budgets, ou associant de=
s=20
lots et des comp=C3=A9tences par exemple), ou non supervis=C3=A9s (type p=
atterns=20
s=C3=A9quentiels);
- de mener une analyse propre =C3=A0 une probl=C3=A9matique (sp=C3=A9cifi=
=C3=A9e sous une=20
forme textuelle), par exemple une =C3=A9tude de march=C3=A9, ou l=E2=80=99=
=C3=A9volution=20
temporelle d=E2=80=99un secteur d=E2=80=99activit=C3=A9;
- de mixer des sources de donn=C3=A9es externes h=C3=A9t=C3=A9rog=C3=A8ne=
s (bases d=E2=80=99appels=20
d=E2=80=99offres type TED1, INSEE, r=C3=A9seaux sociaux, blogs, etc.);
- de d=C3=A9velopper des indicateurs pour la probl=C3=A9matique =C3=A9tud=
i=C3=A9e;
- d=E2=80=99exploiter des outils graphiques pour la visualisation des don=
n=C3=A9es,=20
l=E2=80=99affichage de tendances, l=E2=80=99affichage de r=C3=A9sultats d=
=E2=80=99analyses=20
temporelles et spatiales, etc.

Les travaux cibleront des approches de clustering mixtes, i.e. des=20
approches qui seront susceptibles d=E2=80=99exploiter des contraintes cou=
pl=C3=A9es =C3=A0=20
des techniques d=E2=80=99apprentissage de m=C3=A9trique. Des approches de=
 type=20
apprentissage profond sont bien entendues dans le p=C3=A9rim=C3=A8tre des=
 travaux=20
cibl=C3=A9s. En particulier, des architectures neuronales permettant=20
d=E2=80=99obtenir un plongement des donn=C3=A9es dans un espace m=C3=A9tr=
ique (plongement=20
vectoriel) en prenant en compte certains types de contraintes (=C3=A0=20
identifier dans le cours de la th=C3=A8se) seront mises en =C5=93uvre. D=E2=
=80=99autres=20
approches int=C3=A9grant des principes d=E2=80=99optimisation plus direct=
e associ=C3=A9s =C3=A0=20
des approches de type apprentissage automatique feront =C3=A9galement l=E2=
=80=99objet=20
d=E2=80=99une =C3=A9tude qui pourront =C3=AAtre compar=C3=A9es =C3=A0 la =
pr=C3=A9c=C3=A9dente.
(Note : Ces travaux s=E2=80=99inscrivent dans le cadre d=E2=80=99un parte=
nariat initi=C3=A9=20
en 2015 entre l=E2=80=99entreprise OctopusMind (ex Jurismarch=C3=A9s) et =
l=E2=80=99=C3=A9quipe=20
EXPRESSION du laboratoire de recherche IRISA. Ce partenariat a fait=20
l=E2=80=99objet d=E2=80=99une th=C3=A8se de doctorat centr=C3=A9e sur les=
 espaces de=20
repr=C3=A9sentation (plongements des documents dans des espaces m=C3=A9tr=
iques) et=20
la recherche par similarit=C3=A9 pour la fouille d=E2=80=99appels d=E2=80=
=99offres.)
Profil et comp=C3=A9tences recherch=C3=A9es

Niveau master ou =C3=A9cole d'ing=C3=A9nieur avec des comp=C3=A9tences en=
 informatique=20
et traitement des donn=C3=A9es. Des connaissances en intelligence=20
artificielle (machine learning), fouille de texte, TALN et traitement=20
statistiques des donn=C3=A9es seront appr=C3=A9ci=C3=A9es.
Conditions

La th=C3=A8se sera effectu=C3=A9e en partie dans les locaux de l=E2=80=99=
entreprise=20
OtopusMind (ex Jurismarch=C3=A9s) =C3=A0 Nantes, et en partie dans les lo=
caux de=20
l=E2=80=99IRISA =C3=A0 Vannes.
- L=E2=80=99Entreprise OtopusMind2, =C3=A9ditrice de la plateforme J360.i=
nfo3. de=20
veille =C3=A9conomique, apportera son expertise m=C3=A9tier (=C3=A9quipe =
de veille et=20
=C3=A9quipe de d=C3=A9veloppement logiciel),
- L=E2=80=99=C3=A9quipe EXPRESSION4 du Laboratoire IRISA, site de Vannes=C2=
=A0apportera=20
son savoir-faire en mati=C3=A8re de recherche dans le domaine de la fouil=
le=20
de texte et de machine learning. L=E2=80=99acc=C3=A8s =C3=A0 des moyens d=
e calcul=20
distribu=C3=A9s sera assur=C3=A9 par l=E2=80=99=C3=A9quipe et l=E2=80=99U=
MR IRISA.

R=C3=A9mun=C3=A9ration=C2=A0: 25116 =E2=82=AC brut annuel.
Limite de soumission : 15 Novembre 2018
D=C3=A9marrage de la th=C3=A8se pr=C3=A9vue le 15 F=C3=A9vrier 2019

Contacts=C2=A0:
OctopusMind=C2=A0: Fr=C3=A9d=C3=A9ric Oliveau/Alexandre Garel=C2=A0:
{f.oliveau, a.garel} @OctopusMind.com
IRISA=C2=A0: Pierre-Fran=C3=A7ois Marteau/Nicolas B=C3=A9chet=C2=A0:=20
{pierre-francois.marteau, nicolas.bechet}@irisa.fr

R=C3=A9f=C3=A9rences


[Archambeau et al., 2014] Cedric Archambeau, Balaji Lakshminarayanan,=20
Guillaume Bouchard. Latent IBP compound Dirichlet Allocation. IEEE=20
Transactions on Pattern Analysis and Machine Intelligence, IEEE, pp. 1,=20
page 1, January 2014.

[Bielenko et al., 2004] M. Bilenko, S. Basu, and R. J. Mooney. 2004.=20
Integrating constraints and metric learning in semi-supervised=20
clustering. In Proceedings of the twenty-first international conference=20
on Machine learning (ICML '04). ACM, New York, NY, USA, 2004.

[Cutting et al., 2017] Douglass R. Cutting, David R. Karger, Jan O.=20
Pedersen, and John W. Tukey. 2017. Scatter/Gather: A Cluster-based=20
Approach to Browsing Large Document Collections. SIGIR Forum 51, 2=20
(August 2017), 148-159.

[Dhillon et al., 2004] I. Dhillon, Y. Guan, and B. Kulis. 2005. A fast=20
kernel-based multilevel algorithm for graph clustering. In Proceedings=20
of the eleventh ACM SIGKDD international conference on Knowledge=20
discovery in data mining (KDD '05). ACM, New York, NY, USA, 629-634.

[Kang et al., 2017] Z. Kang, C. Peng and Q. Cheng, "Clustering with=20
Adaptive Manifold Structure Learning," 2017 IEEE 33rd International=20
Conference on Data Engineering (ICDE), San Diego, CA, 2017, pp. 79-82.

[Schultz and Joachims, 2004] M. Schultz and T. Joachims. "Learning a=20
distance metric from relative comparisons." Advances in neural=20
information processing systems (NIPS) (2004), MIT Press, 2004, 41-48.

[Yin et al., 2010] =C2=A0=C2=A0=C2=A0 X. Yin, S. Chen, E. Hu, and D. Zhan=
g.=20
Semi-supervised Clustering with Metric Learning: An Adaptive Kernel=20
Method Pattern Recogn., Elsevier Science Inc., 2010, 43, 1320-1333

[Yin et al., 2012] X. Yin, T. Shu, and Q. Huang. Semi-supervised fuzzy=20
clustering with metric learning and entropy regularization=20
Knowledge-Based Systems, 2012, 35, 304 =E2=80=93 311

--=20
Prof. Pierre-Francois Marteau
http://people.irisa.fr/Pierre-Francois.Marteau/


--------------CADEA4D00676B49915C6E3C7
Content-Type: text/html; charset=utf-8
Content-Transfer-Encoding: quoted-printable

<html>
  <head>

    <meta http-equiv=3D"content-type" content=3D"text/html; charset=3Dutf=
-8">
  </head>
  <body text=3D"#000000" bgcolor=3D"#FFFFFF">
    Offre de th=C3=A8se CIFRE : Clustering adaptatif (semi-supervis=C3=A9=
) de
    donn=C3=A9es =C3=A9conomiques h=C3=A9t=C3=A9rog=C3=A8nes <br>
    <br>
    Contexte scientifique <br>
    <br>
    =C3=80 l'=C3=A8re du d=C3=A9luge des donn=C3=A9es, le clustering inte=
ractif (ou plus
    largement les techniques de classification semi-supervis=C3=A9e ou en=
core
    bas=C3=A9e sur un apprentissage actif)=C2=A0 suscite de plus en plus
    d'attention dans les communaut=C3=A9s de la fouille des donn=C3=A9es =
(en
    particulier l=E2=80=99analyse exploratoire des donn=C3=A9es) et de
    l=E2=80=99apprentissage automatique. L'objectif cibl=C3=A9 est de fai=
re converger
    les r=C3=A9sultats d=E2=80=99un clustering vers un objectif plus ou m=
oins bien
    formalis=C3=A9 en utilisant une supervision limit=C3=A9e. En g=C3=A9n=
=C3=A9ral, le
    clustering semi-supervis=C3=A9 exploite ainsi un nombre limit=C3=A9 d=
=E2=80=99exemples
    (=C3=A9tiquet=C3=A9s), ou un ensemble de contraintes (un sous-ensembl=
e
    d=E2=80=99objets doivent imp=C3=A9rativement =C3=AAtre associ=C3=A9s =
dans un m=C3=AAme cluster
    (ou au contraire doivent =C3=AAtre affect=C3=A9s dans les clusters di=
stincts),
    etc. La complexit=C3=A9 algorithmique est l=E2=80=99un des freins au
    d=C3=A9veloppement des approches de clustering (complexit=C3=A9 souve=
nt
    quadratique). Les approches r=C3=A9centes veillent =C3=A0 ma=C3=AEtri=
ser cette
    complexit=C3=A9. C=E2=80=99est le cas par exemple pour l=E2=80=99appr=
oche
    =E2=80=9C=C3=A9clatement/regroupement=E2=80=9D associ=C3=A9e =C3=A0 u=
n clustering exploratoire
    propos=C3=A9e dans [Cutting et al., 2017]. <br>
    <br>
    Les travaux sur le clustering interactif exploitent des informations
    supervis=C3=A9es qui se r=C3=A9partissant dans l=E2=80=99une des troi=
s orientations
    suivantes : <br>
    <br>
    1) Les approches bas=C3=A9es sur la sp=C3=A9cification de contraintes=
=C2=A0: on
    retrouve dans cette cat=C3=A9gorie les m=C3=A9thodes Kmeans, kernel-K=
means,
    clustering hi=C3=A9rarchique, allocation de Dirichlet Latent (LDA) et
    d=C3=A9riv=C3=A9es [Archambeau et al., 2014], les m=C3=A9thodes de cl=
ustering de
    graphe, le co-clustering, etc. <br>
    <br>
    2) Les approches bas=C3=A9es apprentissage de m=C3=A9trique (metric l=
earning)
    qui adaptent la mesure de similarit=C3=A9 utilis=C3=A9e par l'algorit=
hme de
    classification. Lorsque, par exemple, seules les contraintes par
    paires sont disponibles (telles que les contraintes =C2=ABmust-link=C2=
=BB ou
    =C2=ABcannot-link=C2=BB) [Basu et al., 2009], [Yin et al., 2010] ou [=
Yin et
    al., 2012], les approches bas=C3=A9es sur des graphes peuvent s'av=C3=
=A9rer
    tr=C3=A8s efficaces. Par exemple, [Kang et al., 2017] d=C3=A9veloppen=
t un
    algorithme permettant de clusteriser un graphe (de similarit=C3=A9) e=
n
    tenant compte des structures locales et globales du manifold sur
    lequel se r=C3=A9partissent les donn=C3=A9es. <br>
    <br>
    3) Les approches mixtes=C2=A0: dans [Dhillon et al., 2004] par exempl=
e,
    des approches exploitant des repr=C3=A9sentations vectorielles et des
    graphes sont unifi=C3=A9es en utilisant un algorithme de type kernel
    k-means=C2=A0 pond=C3=A9r=C3=A9. Faisant suite =C3=A0 de nombreux tra=
vaux sur
    l'apprentissage de m=C3=A9trique comme dans [Schultz et Joachims, 200=
4],
    l'int=C3=A9gration des contraintes par paires et de l'apprentissage d=
e
    distance est d=C3=A9velopp=C3=A9e dans un cadre de classification K-m=
eans par
    [Bielenko et al. 2004]. Une approche d'optimisation est alors
    adopt=C3=A9e permettant l'int=C3=A9gration de contraintes et de param=
=C3=A8tres
    m=C3=A9triques dans une seule fonctionnelle. <br>
    Objectifs de la th=C3=A8se <br>
    <br>
    Les travaux de th=C3=A8se propos=C3=A9s concernent le clustering adap=
tatif
    (incluant un processus de semi-supervision) de donn=C3=A9es =C3=A9con=
omiques
    h=C3=A9t=C3=A9rog=C3=A8nes. Il s=E2=80=99agit de concevoir une cha=C3=
=AEne de traitement des
    donn=C3=A9es construite autour d=E2=80=99un clustering interactif qui=
 permet : <br>
    <br>
    - d=E2=80=99exploiter des outils d=E2=80=99extraction d=E2=80=99infor=
mations (structur=C3=A9es ou
    semi-structur=C3=A9es) supervis=C3=A9es de type entit=C3=A9 nomm=C3=A9=
es (le nom d=E2=80=99une
    entreprise, d=E2=80=99une commune ou d=E2=80=99une ville), ou des rel=
ations entre
    concepts (relation associant des lots =C3=A0 des budgets, ou associan=
t
    des lots et des comp=C3=A9tences par exemple), ou non supervis=C3=A9s=
 (type
    patterns s=C3=A9quentiels); <br>
    - de mener une analyse propre =C3=A0 une probl=C3=A9matique (sp=C3=A9=
cifi=C3=A9e sous
    une forme textuelle), par exemple une =C3=A9tude de march=C3=A9, ou
    l=E2=80=99=C3=A9volution temporelle d=E2=80=99un secteur d=E2=80=99ac=
tivit=C3=A9; <br>
    - de mixer des sources de donn=C3=A9es externes h=C3=A9t=C3=A9rog=C3=A8=
nes (bases
    d=E2=80=99appels d=E2=80=99offres type TED1, INSEE, r=C3=A9seaux soci=
aux, blogs, etc.); <br>
    - de d=C3=A9velopper des indicateurs pour la probl=C3=A9matique =C3=A9=
tudi=C3=A9e; <br>
    - d=E2=80=99exploiter des outils graphiques pour la visualisation des
    donn=C3=A9es, l=E2=80=99affichage de tendances, l=E2=80=99affichage d=
e r=C3=A9sultats
    d=E2=80=99analyses temporelles et spatiales, etc. <br>
    <br>
    Les travaux cibleront des approches de clustering mixtes, i.e. des
    approches qui seront susceptibles d=E2=80=99exploiter des contraintes
    coupl=C3=A9es =C3=A0 des techniques d=E2=80=99apprentissage de m=C3=A9=
trique. Des approches
    de type apprentissage profond sont bien entendues dans le p=C3=A9rim=C3=
=A8tre
    des travaux cibl=C3=A9s. En particulier, des architectures neuronales
    permettant d=E2=80=99obtenir un plongement des donn=C3=A9es dans un e=
space
    m=C3=A9trique (plongement vectoriel) en prenant en compte certains ty=
pes
    de contraintes (=C3=A0 identifier dans le cours de la th=C3=A8se) ser=
ont mises
    en =C5=93uvre. D=E2=80=99autres approches int=C3=A9grant des principe=
s d=E2=80=99optimisation
    plus directe associ=C3=A9s =C3=A0 des approches de type apprentissage
    automatique feront =C3=A9galement l=E2=80=99objet d=E2=80=99une =C3=A9=
tude qui pourront =C3=AAtre
    compar=C3=A9es =C3=A0 la pr=C3=A9c=C3=A9dente. <br>
    (Note : Ces travaux s=E2=80=99inscrivent dans le cadre d=E2=80=99un p=
artenariat
    initi=C3=A9 en 2015 entre l=E2=80=99entreprise OctopusMind (ex Jurism=
arch=C3=A9s) et
    l=E2=80=99=C3=A9quipe EXPRESSION du laboratoire de recherche IRISA. C=
e
    partenariat a fait l=E2=80=99objet d=E2=80=99une th=C3=A8se de doctor=
at centr=C3=A9e sur les
    espaces de repr=C3=A9sentation (plongements des documents dans des
    espaces m=C3=A9triques) et la recherche par similarit=C3=A9 pour la f=
ouille
    d=E2=80=99appels d=E2=80=99offres.) <br>
    Profil et comp=C3=A9tences recherch=C3=A9es <br>
    <br>
    Niveau master ou =C3=A9cole d'ing=C3=A9nieur avec des comp=C3=A9tence=
s en
    informatique et traitement des donn=C3=A9es. Des connaissances en
    intelligence artificielle (machine learning), fouille de texte, TALN
    et traitement statistiques des donn=C3=A9es seront appr=C3=A9ci=C3=A9=
es. <br>
    Conditions <br>
    <br>
    La th=C3=A8se sera effectu=C3=A9e en partie dans les locaux de l=E2=80=
=99entreprise
    OtopusMind (ex Jurismarch=C3=A9s) =C3=A0 Nantes, et en partie dans le=
s locaux
    de l=E2=80=99IRISA =C3=A0 Vannes. <br>
    - L=E2=80=99Entreprise OtopusMind2, =C3=A9ditrice de la plateforme J3=
60.info3. de
    veille =C3=A9conomique, apportera son expertise m=C3=A9tier (=C3=A9qu=
ipe de veille
    et =C3=A9quipe de d=C3=A9veloppement logiciel), <br>
    - L=E2=80=99=C3=A9quipe EXPRESSION4 du Laboratoire IRISA, site de
    Vannes=C2=A0apportera son savoir-faire en mati=C3=A8re de recherche d=
ans le
    domaine de la fouille de texte et de machine learning. L=E2=80=99acc=C3=
=A8s =C3=A0 des
    moyens de calcul distribu=C3=A9s sera assur=C3=A9 par l=E2=80=99=C3=A9=
quipe et l=E2=80=99UMR IRISA.
    <br>
    <br>
    R=C3=A9mun=C3=A9ration=C2=A0: 25116 =E2=82=AC brut annuel. <br>
    Limite de soumission : 15 Novembre 2018 <br>
    D=C3=A9marrage de la th=C3=A8se pr=C3=A9vue le 15 F=C3=A9vrier 2019 <=
br>
    <br>
    Contacts=C2=A0: <br>
    OctopusMind=C2=A0: Fr=C3=A9d=C3=A9ric Oliveau/Alexandre Garel=C2=A0: =
<br>
    {f.oliveau, a.garel} @OctopusMind.com <br>
    IRISA=C2=A0: Pierre-Fran=C3=A7ois Marteau/Nicolas B=C3=A9chet=C2=A0:
    {pierre-francois.marteau, <a class=3D"moz-txt-link-abbreviated"
      href=3D"mailto:nicolas.bechet%7D@irisa.fr">nicolas.bechet}@irisa.fr=
</a>
    <br>
    <br>
    R=C3=A9f=C3=A9rences <br>
    <br>
    <br>
    [Archambeau et al., 2014] Cedric Archambeau, Balaji
    Lakshminarayanan, Guillaume Bouchard. Latent IBP compound Dirichlet
    Allocation. IEEE Transactions on Pattern Analysis and Machine
    Intelligence, IEEE, pp. 1, page 1, January 2014. <br>
    <br>
    [Bielenko et al., 2004] M. Bilenko, S. Basu, and R. J. Mooney. 2004.
    Integrating constraints and metric learning in semi-supervised
    clustering. In Proceedings of the twenty-first international
    conference on Machine learning (ICML '04). ACM, New York, NY, USA,
    2004. <br>
    <br>
    [Cutting et al., 2017] Douglass R. Cutting, David R. Karger, Jan O.
    Pedersen, and John W. Tukey. 2017. Scatter/Gather: A Cluster-based
    Approach to Browsing Large Document Collections. SIGIR Forum 51, 2
    (August 2017), 148-159. <br>
    <br>
    [Dhillon et al., 2004] I. Dhillon, Y. Guan, and B. Kulis. 2005. A
    fast kernel-based multilevel algorithm for graph clustering. In
    Proceedings of the eleventh ACM SIGKDD international conference on
    Knowledge discovery in data mining (KDD '05). ACM, New York, NY,
    USA, 629-634. <br>
    <br>
    [Kang et al., 2017] Z. Kang, C. Peng and Q. Cheng, "Clustering with
    Adaptive Manifold Structure Learning," 2017 IEEE 33rd International
    Conference on Data Engineering (ICDE), San Diego, CA, 2017, pp.
    79-82. <br>
    <br>
    [Schultz and Joachims, 2004] M. Schultz and T. Joachims. "Learning a
    distance metric from relative comparisons." Advances in neural
    information processing systems (NIPS) (2004), MIT Press, 2004,
    41-48. <br>
    <br>
    [Yin et al., 2010] =C2=A0=C2=A0=C2=A0 X. Yin, S. Chen, E. Hu, and D. =
Zhang.
    Semi-supervised Clustering with Metric Learning: An Adaptive Kernel
    Method Pattern Recogn., Elsevier Science Inc., 2010, 43, 1320-1333 <b=
r>
    <br>
    [Yin et al., 2012] X. Yin, T. Shu, and Q. Huang. Semi-supervised
    fuzzy clustering with metric learning and entropy regularization
    Knowledge-Based Systems, 2012, 35, 304 =E2=80=93 311 <br>
    <br>
    <span class=3D"moz-txt-tag">--=C2=A0<br>
    </span>Prof. Pierre-Francois Marteau <br>
    <a class=3D"moz-txt-link-freetext"
      href=3D"http://people.irisa.fr/Pierre-Francois.Marteau/">http://peo=
ple.irisa.fr/Pierre-Francois.Marteau/</a><br>
    <br>
  </body>
</html>

--------------CADEA4D00676B49915C6E3C7--
